{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "iris(DNN-tensorflow2.0)-Sequential.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIVId25Van3a"
      },
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5wddLSban3o"
      },
      "source": [
        "## 1) 載入資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA-bjU2pan3p"
      },
      "source": [
        "# df_train = pd.read_csv('./data/Iris.csv')\n",
        "df_train = pd.read_csv('https://github.com/tempzeba/iris-dnn-tensorflow/raw/master/data/Iris.csv')\n",
        "df_train = df_train.drop(labels=['Id'],axis=1) # 移除Id\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1M7a4iian3u"
      },
      "source": [
        "## 2) 手動編碼\n",
        "處理名目資料 (Nominal variables) - 資料前處理\n",
        "依據特徵資料的特性，可以選擇手動編碼或自動編碼。\n",
        "\n",
        "### 使用編碼時機?\n",
        "進行深度學習時，神經網路只能處理數值資料。因此我們需要將所有非數字型態的特徵進行轉換。\n",
        "\n",
        "ex:\n",
        "\n",
        "|  Iris-setosa |  Iris-versicolor | Iris-virginica  |\n",
        "|:---:|:---:|:---:|\n",
        "|  1 | 2  | 3  |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkMEV93an3v"
      },
      "source": [
        "label_map = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
        "\n",
        "#將編碼後的label map存至df_train['Species']中。\n",
        "df_train['Class'] = df_train['Species'].map(label_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjK2EtTXan30"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txpEEPgAan36"
      },
      "source": [
        "## 3) 檢查缺失值\n",
        "使用 numpy 所提供的函式來檢查是否有 NA 缺失值，假設有缺失值使用dropna()來移除。使用的時機在於當只有少量的缺失值適用，若遇到有大量缺失值的情況，或是本身的資料量就很少的情況下建議可以透過機器學習的方法補值來預測缺失值。\n",
        "\n",
        "```python\n",
        "# 移除缺失值\n",
        "train=train.dropna()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpzei1WIan37"
      },
      "source": [
        "df_train = df_train.drop(labels=['Species'],axis=1) # 移除Species\n",
        "# checked missing data\n",
        "print(\"checked missing data(NAN mount):\",len(np.where(np.isnan(df_train))[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNBeqTcUan4A"
      },
      "source": [
        "## 4) 將輸出特徵做one-hot encoding\n",
        "如何對欄位class做one-hot encoding？\n",
        "#### class 的值有0,1,2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQFh4fj0an4C"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(df_train['Class'])\n",
        "y[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OclZM7Wan4I"
      },
      "source": [
        "## 4) 切割訓練集與測試集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjDEttMPan4J"
      },
      "source": [
        "X=df_train.drop(labels=['Class'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKl7fICTan4Q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size=.3 , random_state=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ovl96zhan4T"
      },
      "source": [
        "print('訓練資料: ',X_train.shape)\n",
        "print('測試資料: ',X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB6zvYgJan4Z"
      },
      "source": [
        "## 5) 建立網路模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJvDPRx5an4Z"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q30p2WHxan4d"
      },
      "source": [
        "# 此範例使用 Tensorflow2.0 Sequential API 搭建神經網路。\n",
        "model = Sequential()\n",
        "model.add(Dense(8, Activation('relu'), input_dim=X.shape[-1]))\n",
        "model.add(Dense(16, Activation('relu')))\n",
        "model.add(Dense(3, Activation('softmax')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCfdh7Lgan4h"
      },
      "source": [
        "model.summary()   # Weights = (4+1)*8+(8+1)*16+(16+1)*3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86S7ALLTan4l"
      },
      "source": [
        "# 編譯模型\n",
        "optim = Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optim,\n",
        "              metrics=['acc'])\n",
        "\n",
        "batch_size=1\n",
        "epochs = 50\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    shuffle=True,\n",
        "                    validation_split=0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG1O5ymTan4s"
      },
      "source": [
        "## 6) 觀察訓練結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFUTBafCan4u"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs_ = range(1,len(acc)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PL5GAwan4x"
      },
      "source": [
        "plt.plot(epochs_ , loss , label = 'training loss')\n",
        "plt.plot(epochs_ , val_loss , label = 'val los')\n",
        "plt.title('training and val loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ketuv_Bvan43"
      },
      "source": [
        "plt.clf()\n",
        "plt.plot(epochs_ , acc , label='train accuracy')\n",
        "plt.plot(epochs_ , val_acc , label = 'val accuracy')\n",
        "plt.title('train and val acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR5QIun7an47"
      },
      "source": [
        "## 測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdG9q4M9an47"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "label=np.argmax(y,axis=1)\n",
        "pred =  np.argmax(model.predict(X), axis=1)\n",
        "print(accuracy_score(label, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-t6pvZman4_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}